## DB勉強会用資料

### scraping.py
 DBパフォーマンスには大量のデータが必要です。  
 そこで、Pythonを使ってSUUMOのHPからスクレイピングし、大量の賃貸物件データを取得します。  
 （55万件くらい。本当はもっと欲しいけどデータ取得にも時間がかかるので、これくらいで）  
 こうやって入手したデータは大抵データ分析などに使われます。パフォーマンスチューニングの勉強に使うのは斬新な気がする。  

### create_insert_sql.py
 上記で取得したデータはCSV形式なので、DBのテーブルに流し込めるよう、INSERT文に整形します。  
 データ形式が揃ってなくて、この作業が結構面倒だった。  
 階数に「平家」とか入れたり、最寄り駅までの移動手段に最寄りの商業施設の名前入れたりするのやめてほしい...  

### create_tables.sql
 上記でINSERT文を作ったら、実行する前にテーブルを用意しておいてください。  
 DBはSQL ServerかPostgresQLでお願いします。  
 （MY SQLは結合方法がネステッドループ系しかないのでNG）  

### work.sql
 テーブルを作ってデータも流し込めたら、SQLを実行してみましょう。  
 SELECTしたりUPDATEしたりインデックスを追加してみたり。  
 いろんなパターンを用意しているので、「なぜこのパターンが用意されているのか」を考えながら実行してみてください。  
 細かいことは一緒に手を動かしながら、口頭で説明します。  
